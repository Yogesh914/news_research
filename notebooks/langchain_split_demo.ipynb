{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Text Into Chunks Ready For Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"../data/nvda_news_1.txt\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"The stock of NVIDIA Corp (NASDAQ:NVDA) experienced a daily loss of -3.56% and a 3-month gain of 32.35%. With an Earnings Per Share (EPS) (EPS) of $1.92, the question arises: is the stock significantly overvalued? This article aims to provide a detailed valuation analysis of NVIDIA, offering insights into its financial strength, profitability, growth, and more. We invite you to delve into this comprehensive analysis.\\n\\nCompany Overview\\nWarning! GuruFocus has detected 10 Warning Signs with NVDA. Click here to check it out.\\n\\nNVDA 30-Year Financial Data\\n\\nThe intrinsic value of NVDA\\n\\n\\nNVIDIA Corp (NASDAQ:NVDA) is a leading designer of discrete graphics processing units that enhance the experience on computing platforms. The firm's chips are widely used in various end markets, including PC gaming and data centers. In recent years, NVIDIA has broadened its focus from traditional PC graphics applications such as gaming to more complex and favorable opportunities, including artificial intelligence and autonomous driving, leveraging the high-performance capabilities of its products.\\n\\nCurrently, NVIDIA's stock price stands at $418.01, significantly higher than the GF Value of $310.28, indicating the stock might be overvalued. With a market cap of $1 trillion, the valuation seems steep. The following analysis aims to delve deeper into the company's value.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nUnderstanding the GF Value\\nThe GF Value is a unique measure of the intrinsic value of a stock, calculated based on historical trading multiples, a GuruFocus adjustment factor, and future business performance estimates. If the stock price is significantly above the GF Value Line, it is overvalued, and its future return is likely to be poor. Conversely, if it is significantly below the GF Value Line, its future return will likely be higher.\\n\\nAccording to GuruFocus Value calculation, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. The stock's current price of $418.01 per share and the market cap of $1 trillion further strengthen this assumption.\\n\\nGiven that NVIDIA is significantly overvalued, the long-term return of its stock is likely to be much lower than its future business growth.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nLink: These companies may deliver higher future returns at reduced risk.\\n\\nFinancial Strength of NVIDIA\\nExamining the financial strength of a company is crucial before investing in its stock. Companies with poor financial strength pose a higher risk of permanent loss. NVIDIA's cash-to-debt ratio of 1.27 is worse than 58.04% of companies in the Semiconductors industry. However, NVIDIA's overall financial strength is 8 out of 10, indicating a strong financial position.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nProfitability and Growth\\nConsistent profitability over the long term reduces the risk for investors. NVIDIA, with its profitability ranking of 10 out of 10, has been profitable for the past 10 years. The company's operating margin of 17.37% ranks better than 76.5% of companies in the Semiconductors industry.\\n\\nHowever, growth is a crucial factor in a company's valuation. NVIDIA's growth ranks worse than 52.99% of companies in the Semiconductors industry, with its 3-year average revenue growth rate better than 87.88% of companies in the industry.\\n\\nROIC vs WACC\\nComparing a company's return on invested capital (ROIC) to its weighted average cost of capital (WACC) is an effective way to evaluate its profitability. Over the past 12 months, NVIDIA's ROIC was 20.32 while its WACC was 16.74, suggesting that the company is creating value for its shareholders.\\n\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nIs NVIDIA's Stock Significantly Overvalued? A Comprehensive Valuation Analysis\\nConclusion\\nIn conclusion, NVIDIA (NASDAQ:NVDA) appears to be significantly overvalued. Despite its strong financial condition and profitability, its growth ranks lower than 52.99% of companies in the Semiconductors industry. To learn more about NVIDIA stock, you can check out its 30-Year Financials here.\\n\\nTo find out the high quality companies that may deliver above-average returns, please check out GuruFocus High Quality Low Capex Screener.\\n\\nThis article first appeared on GuruFocus.\", metadata={'source': 'data/nvda_news_1.txt'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'data/nvda_news_1.txt'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "loader = CSVLoader(\"../data/movies.csv\", source_column=\"title\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'Doctor Strange in the Multiverse of Madness', 'row': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredURLLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredURLLoader(urls=[\n",
    "    \"https://news.wisc.edu/uw-center-for-healthy-minds-will-research-machine-learning-predictions-of-well-being/\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = loader.load()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='UW Center for Healthy Minds will research machine learning predictions of well-being\\n\\nMay 22, 2023\\n\\nBy Heather Harris\\n\\nFor news media\\n        \\n        More information\\n\\nThe multi-phase project will begin with a research study with human participants to predict their momentary emotional states, especially when they are feeling distracted, lonely, self-critical or unfulfilled, times when they may benefit from micro-support. iStock photo\\n\\nHigh rates of depression, anxiety, loneliness and lack of purpose are taking a toll on Americans’ mental and physical health, with wide-ranging negative consequences. Unfortunately, many of those most in need of mental health services are unable to access them through traditional means.\\n\\nResearchers at the University of Wisconsin–Madison’s Center for Healthy Minds are working on one possible solution that leverages artificial intelligence to deliver personalized well-being content through a person’s mobile device when they need it most.\\n\\n“We hope to discover how to offer supportive well-being practices on mobile phones that are sensitive to what a person is feeling and easy to engage with in the moment,” says Christy Wilson-Mendenhall, co-investigator on the new, two-year project, which is set to launch this year.\\n\\nSupported by a $3 million-plus grant from the Defense Advanced Research Projects Agency (DARPA), the project aims to discover and develop technologies that in the future may inform the delivery of algorithm-based micro-supports — short well-being practices like mindful breathing that may help in the moment — through a version of the Healthy Minds program, currently used in the Healthy Minds Program smartphone app.\\n\\nThe multi-phase project will begin with a research study with human participants to predict their momentary emotional states, especially when they are feeling distracted, lonely, self-critical or unfulfilled, times when they may benefit from micro-support.\\n\\nThis initial step will help inform the development of machine learning tools and algorithms for the new platform. The researchers intend to develop their micro-support framework and content through testing with a diverse group of participants to examine whether users find the micro-supports relevant, timely and potentially helpful. The end goal is a platform that can deliver micro-supports based on an algorithmic trigger.\\n\\n“In many ways, we are at the very beginning of finding how best to incorporate mobile technology into our daily lives in ways that support, rather than reduce, our well-being”\\n\\nSimon Goldberg\\n\\nIn practice, the app will gather information from consenting participants through in-the-moment “experience sampling.” This sampling will entail brief, user-created videos in response to prompts like “I am feeling…,” as well as passive mobile data like geolocation and activity patterns.\\n\\nResearchers will analyze the data to assess users’ well-being in terms of the four pillars of the Healthy Minds well-being framework: awareness, connection, insight and purpose. Previous research has linked these pillars to trainable skills associated with well-being. This analysis will inform delivery of very short, personalized “in-the-moment” well-being practices to keep users engaged in cultivating well-being behaviors throughout the day. These micro-supports will be easy and minimally disruptive, allowing users to be fully present with their day-to-day activities.\\n\\nThis novel research furthers the development of an evidence-based, scalable option in personalized mobile well-being interventions, which to date have used a one-size-fits-all approach with inaccessible costs and time commitments, resulting in early drop-off by users.\\n\\n“There are rich streams of data that can be acquired through low-effort activities that individuals are accustomed to doing on mobile phones like creating a short video, and also completely passively from their phones, with their consent,” says Richard J. Davidson, founder of Center for Healthy Minds. “This type of data may be an informative context for tailoring delivery of specific micro-supports that may increase well-being.”\\n\\nDavidson believes micro-supports delivered at the right time and place may have an outsized impact on well-being.\\n\\n“Imagine how an anxious student receiving a prompt for a 30-second mindful moment right before a final exam might perform better, or how a meeting might unfold after a leader receives an appreciation micro-intervention right beforehand,” says Davidson. “There are endless opportunities that can be tested in real-world settings.”\\n\\nThe study will position researchers to eventually conduct a randomized control trial to test the efficacy of micro-supports triggered via machine learning tools.\\n\\n“In many ways, we are at the very beginning of finding how best to incorporate mobile technology into our daily lives in ways that support, rather than reduce, our well-being,” says Simon Goldberg, an assistant professor of counseling psychology at UW–Madison and core faculty at CHM. “This project and the kinds of micro-supports that might be triggered based on what we learn can be part of developing technological tools that promote a healthy quality of mind.”\\n\\nFuture aims include continuing research and eventually releasing a platform for widespread public use through a range of web, mobile and wearable devices.\\n\\nThe Center for Healthy Minds at the University of Wisconsin–Madison is a global leader in conducting rigorous scientific research. CHM aims to cultivate well-being and relieve suffering through a scientific understanding of the mind, with a vision of a kinder, wiser, more compassionate world. To learn more, please visit centerhealthyminds.org.\\n\\nThe free, science-based Healthy Minds meditation app developed in partnership with Healthy Minds Innovations was ranked by the New York Times Wirecutter as one of the best meditation apps of 2023.\\n\\nShare via Facebook\\n\\nShare via Twitter\\n\\nShare via Linked In\\n\\nShare via email', metadata={'source': 'https://news.wisc.edu/uw-center-for-healthy-minds-will-research-machine-learning-predictions-of-well-being/'})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
